{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Classification\n",
    "Uses previously obtained number of GM, WM, & CSF pixels to train a logistic-regression classifier to find relationship between GM, WM, CSF and age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import os.path as op\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Scikit-learn\n",
    "from sklearn.utils import compute_class_weight\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import PrecisionRecallDisplay, ConfusionMatrixDisplay, classification_report, make_scorer, balanced_accuracy_score, fbeta_score, precision_recall_curve, precision_score, recall_score, accuracy_score, roc_auc_score, f1_score, matthews_corrcoef, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pathing\n",
    "path = '../'\n",
    "\n",
    "images_path = Path(path, 'data', 'images')\n",
    "masks_path = Path(path, 'data', 'masks')\n",
    "segs_path = Path(path, 'data', 'segs_refs')\n",
    "metadata_path = Path(path, 'data', 'meta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Loop\n",
    "Uses a logistic regression classifier to find relationship between age and GM, WM, & CSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>CSF</th>\n",
       "      <th>GM</th>\n",
       "      <th>WM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CC110033</td>\n",
       "      <td>24</td>\n",
       "      <td>MALE</td>\n",
       "      <td>32255</td>\n",
       "      <td>88877</td>\n",
       "      <td>53097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CC110037</td>\n",
       "      <td>18</td>\n",
       "      <td>MALE</td>\n",
       "      <td>23522</td>\n",
       "      <td>93552</td>\n",
       "      <td>53059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CC110045</td>\n",
       "      <td>24</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>22655</td>\n",
       "      <td>97481</td>\n",
       "      <td>49497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CC110056</td>\n",
       "      <td>22</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>20673</td>\n",
       "      <td>86147</td>\n",
       "      <td>49316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CC110062</td>\n",
       "      <td>20</td>\n",
       "      <td>MALE</td>\n",
       "      <td>20466</td>\n",
       "      <td>110771</td>\n",
       "      <td>60077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subject  age  gender    CSF      GM     WM\n",
       "0  CC110033   24    MALE  32255   88877  53097\n",
       "1  CC110037   18    MALE  23522   93552  53059\n",
       "2  CC110045   24  FEMALE  22655   97481  49497\n",
       "3  CC110056   22  FEMALE  20673   86147  49316\n",
       "4  CC110062   20    MALE  20466  110771  60077"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Reading in data from CSV file\n",
    "data_table = pd.read_csv(Path(path, 'data', 'brain_data.csv'))\n",
    "data_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(652, 3)\n",
      "(652,)\n"
     ]
    }
   ],
   "source": [
    "# Extracting X - a 2D matrix of features (Gray matter, white matter, & CSF pixels)\n",
    "X = data_table[['GM', 'WM', 'CSF']].values\n",
    "# Extracting Y - a 1D array of labels (age)\n",
    "y = data_table['age'].values\n",
    "\n",
    "# Confirming shape of X and Y match\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mstratify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\masci\\.conda\\envs\\neuro\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    212\u001b[0m         )\n\u001b[0;32m    213\u001b[0m     ):\n\u001b[1;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    224\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\masci\\.conda\\envs\\neuro\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2670\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2666\u001b[0m         CVClass \u001b[38;5;241m=\u001b[39m ShuffleSplit\n\u001b[0;32m   2668\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m-> 2670\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstratify\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2672\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m   2673\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[0;32m   2674\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m   2675\u001b[0m     )\n\u001b[0;32m   2676\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\masci\\.conda\\envs\\neuro\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1746\u001b[0m, in \u001b[0;36mBaseShuffleSplit.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   1716\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[0;32m   1717\u001b[0m \n\u001b[0;32m   1718\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;124;03mto an integer.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1745\u001b[0m X, y, groups \u001b[38;5;241m=\u001b[39m indexable(X, y, groups)\n\u001b[1;32m-> 1746\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_indices(X, y, groups):\n\u001b[0;32m   1747\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m train, test\n",
      "File \u001b[1;32mc:\\Users\\masci\\.conda\\envs\\neuro\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2147\u001b[0m, in \u001b[0;36mStratifiedShuffleSplit._iter_indices\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   2145\u001b[0m class_counts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbincount(y_indices)\n\u001b[0;32m   2146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmin(class_counts) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 2147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2148\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe least populated class in y has only 1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m member, which is too few. The minimum\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2150\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m number of groups for any class cannot\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2151\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be less than 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2152\u001b[0m     )\n\u001b[0;32m   2154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m<\u001b[39m n_classes:\n\u001b[0;32m   2155\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2156\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe train_size = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m should be greater or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mequal to the number of classes = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (n_train, n_classes)\n\u001b[0;32m   2158\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y,\n",
    "                                                    stratify=y,\n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42,\n",
    "                                                    shuffle=True\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1, 0.2, 0.3],\n",
       "       [0.4, 0.5, 0.6],\n",
       "       [0.7, 0.8, 0.9],\n",
       "       [1. , 1.1, 1.2]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[0.1, 0.2, 0.3], [0.4, 0.5, 0.6], [0.7, 0.8, 0.9], [1.0, 1.1, 1.2]])\n",
    "X # Each row = sample, each column = feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler() # Should be PCA instead?  https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA\n",
    "vectorizer = Vectorizer()\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=10000, tol=0.1) # Hyperparameters to be tuned\n",
    "\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(D, \n",
    "                                                    labels,\n",
    "                                                    stratify=labels,\n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42,\n",
    "                                                    shuffle=True\n",
    "                                                    )\n",
    "\n",
    "clf = Pipeline([('Vectorizer', vectorizer),\n",
    "                ('Scaler', scaler), # Should be PCA instead?\n",
    "                ('logistic', log_reg)                                 \n",
    "                ])\n",
    "\n",
    "# Cross validating\n",
    "cv_cv = cross_validate(clf, X_train, y_train, \n",
    "                        cv=cv,\n",
    "                        scoring=scoring,\n",
    "                        return_train_score=True, # Determines if Training scores are included in .cv_results_\n",
    "                        n_jobs=5,\n",
    "                        error_score='raise' # For debugging purposes\n",
    "                        )\n",
    "\n",
    "print('Training Classifier')\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "print('Predicting...')\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print('Scoring...')        \n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix Generation and Visualization within the loop -> saved to csv as \"[[TN, FN] [FP, TP]]\"\n",
    "cm = confusion_matrix(y_test, y_pred, labels=clf.classes_)\n",
    "cmd = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\n",
    "cmd.plot()\n",
    "plt.title(subject + '_' + str(contr).replace('/', '_') + '_' + c_name)\n",
    "plt.show()\n",
    "\n",
    "# Saving CV results to a  DataFrame \n",
    "results = pd.DataFrame(cv_cv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Reference Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%xmode Verbose\n",
    "\n",
    "scaler = StandardScaler()\n",
    "vectorizer = Vectorizer()\n",
    "\n",
    "# Making the crossvalidation to be used in the RandomizedSearch\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "for subject in subjects:\n",
    "    print('\\n-------\\n\\033[;40m' + subject + '\\033[m')\n",
    "    \n",
    "    # Clearing out the saved data for each participant\n",
    "    data_table = pd.DataFrame()\n",
    "    data_table_list = []\n",
    "    \n",
    "    for contr, conds in contrasts.items():\n",
    "        print('-------\\n\\033[94;40m' + contr + '\\033[m')\n",
    "        subj_epochs = epochs[subject][conds]\n",
    "        \n",
    "        # Create a list of labels from event codes mapped to event_id\n",
    "        event_id_rev = dict(zip(subj_epochs.event_id.values(), subj_epochs.event_id.keys()))\n",
    "        labels_all = [event_id_rev[e] for e in subj_epochs.events[:, 2]]\n",
    "        labels_all = pd.DataFrame(labels_all)[0].str.split('/', expand=True).rename(columns={0:'Colour', 1:'Orientation', 2:'Type', 3:'Status', 4:'Location'} )\n",
    "        label_map = {'Target':1, 'Standard':0}\n",
    "        labels_all['labels'] = labels_all['Status'].map(label_map)\n",
    "        labels = labels_all['labels']\n",
    "        \n",
    "        # Extract data from subj_epochs and vectorize \n",
    "        D = subj_epochs.get_data()\n",
    "        \n",
    "        # Create train-test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(D, \n",
    "                                                            labels,\n",
    "                                                            stratify=labels,\n",
    "                                                            test_size=cl_p['test_size'], \n",
    "                                                            random_state=42,\n",
    "                                                            shuffle=True\n",
    "                                                           )\n",
    "\n",
    "        # Classifier Loop\n",
    "        for c_name, c in classifiers.items():\n",
    "            print('-------\\nRunning classifier: \\033[1;91;40m' + c_name + '\\033[m')\n",
    "\n",
    "            # Making the Pipeline\n",
    "            clf = Pipeline([('Vectorizer', vectorizer),\n",
    "                             ('Scaler', scaler),\n",
    "                             (c_name, c)                                 \n",
    "                             ])\n",
    "\n",
    "            # Cross validating\n",
    "            cv_cv = cross_validate(clf, X_train, y_train, \n",
    "                                   cv=cv,\n",
    "                                   scoring=scoring,\n",
    "                                   return_train_score=True, # Determines if Training scores are included in .cv_results_\n",
    "                                   n_jobs=5,\n",
    "                                   error_score='raise' # For debugging purposes\n",
    "                                   )\n",
    "\n",
    "            print('Training Classifier')\n",
    "            clf = clf.fit(X_train, y_train)\n",
    "\n",
    "            print('Predicting...')\n",
    "            y_pred = clf.predict(X_test)\n",
    "\n",
    "            print('Scoring...')        \n",
    "            print(classification_report(y_test, y_pred))\n",
    "\n",
    "            # Confusion Matrix Generation and Visualization within the loop -> saved to csv as \"[[TN, FN] [FP, TP]]\"\n",
    "            cm = confusion_matrix(y_test, y_pred, labels=clf.classes_)\n",
    "            cmd = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\n",
    "            cmd.plot()\n",
    "            plt.title(subject + '_' + str(contr).replace('/', '_') + '_' + c_name)\n",
    "            plt.show()\n",
    "\n",
    "            # Saving CV results to a DataFrame \n",
    "            results = pd.DataFrame(cv_cv)\n",
    "\n",
    "            data_table_list.append(pd.DataFrame({'participant_id': subject,\n",
    "                                              'Condition': contr,\n",
    "                                              'Classifier': c_name,\n",
    "\n",
    "                                              # Confusion_matrix saved in format: [[TN, FN] [FP, TP]]\n",
    "                                              'Confusion_Matrix': str(cm),                                                 \n",
    "\n",
    "                                              'CV_Train_Bal_Accuracy': results['train_Bal_Acc'].round(3) * 100,\n",
    "                                              'CV_Test_Bal_Accuracy': results['test_Bal_Acc'].round(3) * 100,\n",
    "                                              'Test_Bal_Accuracy': round(balanced_accuracy_score(y_test, y_pred), 3) * 100,\n",
    "\n",
    "                                              'CV_Train_Accuracy': results['train_Acc'].round(3) * 100,\n",
    "                                              'CV_Test_Accuracy': results['test_Acc'].round(3) * 100,\n",
    "                                              'Test_Accuracy': round(accuracy_score(y_test, y_pred), 3) * 100, \n",
    "\n",
    "                                              'CV_Train_Precision': results['train_Prec'].round(3) * 100,\n",
    "                                              'CV_Test_Precision': results['test_Prec'].round(3) * 100,                                                \n",
    "                                              'Test_Precision': round(precision_score(y_test, y_pred, zero_division=0), 3) * 100,    \n",
    "\n",
    "                                              'CV_Train_Matthews_coef': results['train_Matthews_Coef'].round(3),\n",
    "                                              'CV_Test_Matthews_coef': results['test_Matthews_Coef'].round(3),\n",
    "                                              'Matthews_Coef': round(matthews_corrcoef(y_test, y_pred), 3),\n",
    "\n",
    "                                              'CV_Train_Recall': results['train_Recall'].round(3) * 100,\n",
    "                                              'CV_Test_Recall': results['test_Recall'].round(3) * 100,\n",
    "                                              'Test_recall': round(recall_score(y_test, y_pred), 3) * 100,\n",
    "\n",
    "                                              'CV_Train_Fbeta_0.5': results['train_Fbeta_0.5'].round(3),\n",
    "                                              'CV_Train_Fbeta_0.5': results['train_Fbeta_0.5'].round(3),\n",
    "                                              'Fbeta_0.5': round(fbeta_score(y_test, y_pred, beta = 0.5, zero_division=0), 3),\n",
    "\n",
    "                                              'CV_Train_Fbeta_1.5': results['train_Fbeta_1.5'].round(3),\n",
    "                                              'CV_Test_Fbeta_1.5': results['test_Fbeta_1.5'].round(3),\n",
    "                                              'Fbeta_1.5': round(fbeta_score(y_test, y_pred, beta = 1.5, zero_division=0), 3),\n",
    "\n",
    "                                              'CV_Train_F1': results['train_F1_score'].round(3),\n",
    "                                              'CV_Test_F1': results['test_F1_score'].round(3),\n",
    "                                              'F1_score': round(f1_score(y_test, y_pred, zero_division=0), 3),\n",
    "\n",
    "                                              'CV_Train_ROC_AUC': results['train_ROC'].round(3),\n",
    "                                              'CV_Test_ROC_AUC': results['test_ROC'].round(3),                                             \n",
    "                                              'Test_ROC_AUC': round(roc_auc_score(y_test, y_pred), 3),\n",
    "\n",
    "                                              'Mean Fit Time': results['fit_time'].round(3),\n",
    "                                              'Mean Score Time': results['score_time'].round(3)\n",
    "                                             }, index=[0]\n",
    "                                            )\n",
    "                               )\n",
    "\n",
    "    # Saving Data to CSV Per Participant\n",
    "    data_table = pd.concat(data_table_list)\n",
    "    data_table.to_csv(f'{str(subject)} new_Data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psychopy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
